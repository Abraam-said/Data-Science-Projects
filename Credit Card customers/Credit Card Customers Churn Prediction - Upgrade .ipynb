{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd69b584",
   "metadata": {},
   "source": [
    "<div style=\" text-align: center; justify-content: center; align-items: center; background-color: #FAF884\n",
    "; padding: 10px;  border-radius: 10px;\">\n",
    "    <h1 style=\"color: black;  margin-top: 9px; margin-bottom: 9px; \"><center>\n",
    "        Credit Card Customers Churn Prediction💡\n",
    "</center></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89b1fe",
   "metadata": {},
   "source": [
    "# Introduction 📖"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def255ae",
   "metadata": {},
   "source": [
    "The bank's manager is concerned about customers leaving their credit card services. **The goal** of this analysis is to create a model that predicts whether a customer is likely to leave or not. This prediction will help the bank proactively engage with at-risk customers, provide better services, and ultimately reduce customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d0de8",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "# Table of Contents 📑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674932a",
   "metadata": {},
   "source": [
    "> - [1 - Import Libraries 📚](#1)\n",
    "> - [2 - Data Exploration 🔎](#2)\n",
    "> - [3 - Exploratory Data Analysis 📊](#3)\n",
    ">    - [3.1- Univariate Analysis](#3.1)\n",
    ">    - [3.2- Bivariate Analysis](#3.2)\n",
    "> - [4 - Data Preprocessing ⚒️](#4)\n",
    ">    - [4.1- Handling Missing Data](#4.1)\n",
    ">    - [4.2- Handling Outliers](#4.2)\n",
    ">    - [4.3- Handling Categorical Data](#4.3)\n",
    ">    - [4.4- Data Split to Train and Test Sets](#4.4)\n",
    ">    - [4.5- Handling Imbalanced Data](#4.5)\n",
    ">    - [4.6- Feature Scaling](#4.6)\n",
    "> - [5- Models Training and Evaluation ⚙️](#5)\n",
    ">    - [5.1- K-fold Cross-Validation Evaluation](#5.1)\n",
    ">    - [5.2- Training the Chosen Model (XGBoost Classifier)](#5.2)\n",
    "> - [6- Hyperparameter Tuning 🛠️](#6)\n",
    ">    - [6.1- ROC Curve for Final Model (XGBoost Classifier)](#6.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9641b1",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    "<a class=\"anchor\"  id=\"1\"></a>\n",
    "# 1- Import Libraries 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Data Preprocessing Libraries\n",
    "from datasist.structdata import detect_outliers\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Machine Learing (classification models) Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_regression, RFE, SelectFromModel\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, roc_curve, roc_auc_score \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50e16f",
   "metadata": {},
   "source": [
    "-------------------\n",
    "<a class=\"anchor\"  id=\"2\"></a>\n",
    "# 2- Data Exploration🔎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082afbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BankChurners.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011661ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing all column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with unusual names\n",
    "df = df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "             'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e9986",
   "metadata": {},
   "source": [
    "### Feature Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7330a",
   "metadata": {},
   "source": [
    "> - **`CLIENTNUM`** : Unique client identifier.\n",
    "> - **`Attrition_Flag`** : Indicates whether the customer's account is active or has churned.\n",
    "> - **`Customer_Age`** : Age of the customer.\n",
    "> - **`Gender`** : Gender of the customer.\n",
    "> - **`Dependent_count`** : Number of dependents of the customer.\n",
    "> - **`Education_Level`** : Educational level of the customer.\n",
    "> - **`Marital_Status`** : Marital status of the customer.\n",
    "> - **`Income_Category`** : Income category of the customer.\n",
    "> - **`Card_Category`** : Category of the credit card held by the customer.\n",
    "> - **`Months_on_book`** : Number of months the customer has been a bank client.\n",
    "> - **`Total_Relationship_Count`** : Total number of bank products held by the customer.\n",
    "> - **`Months_Inactive_12_mon`** : Number of months with inactivity in the last 12 months.\n",
    "> - **`Contacts_Count_12_mon`** : Number of contacts with the bank in the last 12 months.\n",
    "> - **`Credit_Limit`** : Credit limit on the credit card.\n",
    "> - **`Total_Revolving_Bal`** : Total revolving balance on the credit card.\n",
    "> - **`Avg_Open_To_Buy`** : Average open to buy credit line on the credit card.\n",
    "> - **`Total_Amt_Chng_Q4_Q1`** : Change in transaction amount over the last four quarters.\n",
    "> - **`Total_Trans_Amt`** : Total transaction amount in the last 12 months.\n",
    "> - **`Total_Trans_Ct`** : Total transaction count in the last 12 months.\n",
    "> - **`Total_Ct_Chng_Q4_Q1`** : Change in transaction count over the last four quarters.\n",
    "> - **`Avg_Utilization_Ratio`** : Average utilization ratio of the credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3777d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping CLIENTNUM column as it's a unique identifier and not useful for predictions.\n",
    "df = df.drop( 'CLIENTNUM', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicated values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c371c",
   "metadata": {},
   "source": [
    "- Data doesn't contain any duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06027200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking count the number of unique values in each column of the data\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796225fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive analysis for numerical data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76125e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive analysis for categorical data\n",
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebac3196",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "<a class=\"anchor\"  id=\"3\"></a>\n",
    "# 3- Exploratory Data Analysis 📊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting columns into Categorical and Numerical Features\n",
    "categorical_features = [\n",
    "    'Attrition_Flag', 'Gender', 'Education_Level', 'Marital_Status',\n",
    "    'Income_Category', 'Card_Category'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'Customer_Age', 'Dependent_count', 'Months_on_book', \n",
    "    'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
    "    'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
    "    'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
    "    'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c8bf1",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"3.1\"></a>\n",
    "## 3.1- Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebd55d",
   "metadata": {},
   "source": [
    "### Exploration: Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58240243",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df, names='Attrition_Flag', \n",
    "             title='Attrition Flag Distribution',\n",
    "             color_discrete_sequence=['#ff7f0e', '#3498db'],# Setting custom color\n",
    "            )\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "\n",
    "# Show the pie chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df, names='Gender', \n",
    "             title='Gender Distribution',\n",
    "             color_discrete_sequence=['#ff7f0e', '#3498db'],# Setting custom color\n",
    "            )\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "\n",
    "# Show the pie chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='Education_Level', \n",
    "                   title='Education Level Distribution',\n",
    "                   color_discrete_sequence=['#3498db'],  # Setting custom color\n",
    "                  )\n",
    "\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84946345",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='Marital_Status', \n",
    "                   title='Marital Status Distribution',\n",
    "                   color_discrete_sequence=['#3498db'],  # Setting custom color\n",
    "                  )\n",
    "\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac012103",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='Income_Category', \n",
    "                   title='Income Category Distribution',\n",
    "                   color_discrete_sequence=['#3498db'],  # Setting custom color\n",
    "                  )\n",
    "\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='Card_Category', \n",
    "                   title='Card Category Distribution',\n",
    "                   color_discrete_sequence=['#3498db'],  # Setting custom color\n",
    "                  )\n",
    "\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a316b72",
   "metadata": {},
   "source": [
    "### Exploration: Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a98c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with specified dimensions\n",
    "fig, axes = plt.subplots(7, 2, figsize=(14, 20))  # Adjust the figsize according to your preference\n",
    "\n",
    "# Plot distribution plots for each skewed column\n",
    "for i, column in enumerate(numerical_features):\n",
    "    row = i // 2  # Calculate the row for the subplot\n",
    "    col = i % 2   # Calculate the column for the subplot\n",
    "    sns.boxplot(data=df, x=column, ax=axes[row, col], palette='Set2', orient='h', color='skyblue')\n",
    "    axes[row, col].set_title(f'Distribution of {column}', fontsize=14)\n",
    "\n",
    "# Remove any empty subplots if there are fewer numerical features than expected\n",
    "for i in range(len(numerical_features), 7 * 2):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5850221",
   "metadata": {},
   "source": [
    "### Skewed Continuous Features Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with specified dimensions\n",
    "fig, axes = plt.subplots(7, 2, figsize=(14, 20))  # Adjust the figsize according to your preference\n",
    "\n",
    "# Plot distribution plots for each skewed column\n",
    "for i, column in enumerate(numerical_features):\n",
    "    row = i // 2  # Calculate the row for the subplot\n",
    "    col = i % 2   # Calculate the column for the subplot\n",
    "    sns.histplot(data=df, x=column, kde=True, ax=axes[row, col], color='skyblue')\n",
    "    axes[row, col].set_title(f'Distribution of {column}', fontsize=14)\n",
    "\n",
    "# Remove any empty subplots if there are fewer numerical features than expected\n",
    "for i in range(len(numerical_features), 7 * 2):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298e2b1",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "<a class=\"anchor\"  id=\"3.2\"></a>\n",
    "## 3.2- Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29a12f",
   "metadata": {},
   "source": [
    "### What is the relationship between churn status and other categorical variables like Gender, Education Level, Marital Status, and Income Category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d0e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='Gender', color='Attrition_Flag',\n",
    "             title='Churn Rates by Gender',\n",
    "             labels={'country': 'Country', 'state': 'Project State'},\n",
    "             template='plotly_white', barmode='group',\n",
    "             color_discrete_sequence=['#ff7f0e', '#3498db']\n",
    "            )\n",
    "\n",
    "# Customizing marker appearance\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcddfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='Education_Level', color='Attrition_Flag',\n",
    "             title='Churn Rates by Gender',\n",
    "             labels={'country': 'Country', 'state': 'Project State'},\n",
    "             template='plotly_white', barmode='group',\n",
    "             color_discrete_sequence=['#ff7f0e', '#3498db']\n",
    "            )\n",
    "\n",
    "# Customizing marker appearance\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e18458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='Marital_Status', color='Attrition_Flag',\n",
    "             title='Churn Rates by Gender',\n",
    "             labels={'country': 'Country', 'state': 'Project State'},\n",
    "             template='plotly_white', barmode='group',\n",
    "             color_discrete_sequence=['#ff7f0e', '#3498db']\n",
    "            )\n",
    "\n",
    "# Customizing marker appearance\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d19864",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='Income_Category', color='Attrition_Flag',\n",
    "             title='Churn Rates by Gender',\n",
    "             labels={'country': 'Country', 'state': 'Project State'},\n",
    "             template='plotly_white', barmode='group',\n",
    "             color_discrete_sequence=['#ff7f0e', '#3498db']\n",
    "            )\n",
    "\n",
    "# Customizing marker appearance\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27b945",
   "metadata": {},
   "source": [
    "### How does customer age correlate with churn status ? Are younger or older customers more likely to churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a histogram using Plotly Express to visualize the relationship between age and the risk of heart attack\n",
    "fig = px.histogram(df, x='Customer_Age', color='Attrition_Flag', title='The Effect of Age on Risk of Heart Attack (Output)',\n",
    "                   labels={'age': 'Age', 'output': 'Output'}, \n",
    "                   marginal='box', barmode='group',\n",
    "                   color_discrete_sequence=['#ff7f0e', '#3498db']\n",
    "                 )\n",
    "\n",
    "# Customizing marker appearance\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ad01b",
   "metadata": {},
   "source": [
    "### Is there a relationship between credit card utilization and churn status ? Do customers with higher card utilization have a higher likelihood of churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df, y='Avg_Utilization_Ratio', x='Attrition_Flag', \n",
    "                color='Attrition_Flag', \n",
    "                title='Relationship Between Credit Card Utilization and Churn Status',\n",
    "                color_discrete_sequence=['#ff7f0e', '#3498db'],\n",
    "                labels={'Avg_Utilization_Ratio': 'Credit Card Utilization Ratio', 'Attrition_Flag': 'Churn Status'})\n",
    "\n",
    "# Format the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(title='Credit Card Utilization Ratio', zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf212539",
   "metadata": {},
   "source": [
    "### Is there a correlation between credit limit and churn status ? Do customers with higher credit limits tend to stay with the bank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bf706",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df, y='Credit_Limit', x='Attrition_Flag', \n",
    "                 color='Attrition_Flag', \n",
    "                 title='Correlation Between Credit Limit and Churn Status',\n",
    "                 color_discrete_sequence=['#ff7f0e', '#3498db'],\n",
    "                 labels={'Credit_Limit': 'Credit Limit', 'Attrition_Flag': 'Churn Status'},)\n",
    "\n",
    "# Format the layout\n",
    "fig.update_layout(\n",
    "    yaxis=dict(showgrid=False, zeroline=False),\n",
    "    xaxis=dict(title='Credit Limit', zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e0626e",
   "metadata": {},
   "source": [
    "### Does the number of contacts with the bank in the last 12 months influence churn? Are customers who are contacted more frequently less likely to churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fdb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df, y='Contacts_Count_12_mon', x='Attrition_Flag', \n",
    "                color='Attrition_Flag', \n",
    "                title='Influence of Contacts Count on Churn Status',\n",
    "                color_discrete_sequence=['#ff7f0e', '#3498db'],\n",
    "                labels={'Contacts_Count_12_mon': 'Number of Contacts in Last 12 Months', 'Attrition_Flag': 'Churn Status'},\n",
    "                category_orders={'Attrition_Flag': ['Existing Customer', 'Attrited Customer']})  \n",
    "\n",
    "# Customizing marker appearance\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "# Format the layout\n",
    "fig.update_layout(\n",
    "    yaxis=dict(title='Number of Contacts in Last 12 Months', showgrid=False, zeroline=False),\n",
    "    xaxis=dict(title='Churn Status', zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233, 233, 233)',\n",
    "    plot_bgcolor='rgb(233, 233, 233)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88442c",
   "metadata": {},
   "source": [
    "------------------\n",
    "<a class=\"anchor\"  id=\"4\"></a>\n",
    "# 4- Data Preprocessing ⚒️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eac9495",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"4.1\"></a>\n",
    "## 4.1- Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values in data\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d853cf",
   "metadata": {},
   "source": [
    "- Data does not contain any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81726231",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"4.2\"></a>\n",
    "## 4.2- Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67642304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in numerical features\n",
    "outliers_indices = detect_outliers(df, features=numerical_features, n=1.5)\n",
    "number_of_outliers = len(outliers_indices)\n",
    "\n",
    "# Print the number of outliers\n",
    "print(f'Number of outliers: {number_of_outliers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all Outliers\n",
    "df = df.drop(outliers_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eaccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset Shape After Removing Outliers {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2fdcfe",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"4.3\"></a>\n",
    "## 4.3- Handling Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b39a9",
   "metadata": {},
   "source": [
    "- **Nominal**: Categories without a meaningful order or ranking like (**Attrition Flag, Gender, Marital Status**).\n",
    "- **Ordinal**: Categories with a meaningful order or ranking like (**Education Level, Income Category, Card Category**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Ordinal Features with pandas `map` method.\n",
    "\n",
    "attrition_flag_dic = {\n",
    "    'Existing Customer' : 0,\n",
    "    'Attrited Customer' : 1\n",
    "}\n",
    "\n",
    "edu_level_dic = {  \n",
    "    'Unknown': 0, \n",
    "    'Uneducated': 1, \n",
    "    'High School': 2, \n",
    "    'College': 3,\n",
    "    'Post-Graduate': 4, \n",
    "    'Graduate': 5, \n",
    "    'Doctorate': 6\n",
    "} \n",
    "\n",
    "income_cat_dic = {\n",
    "    'Unknown': 0,\n",
    "    'Less than $40K': 1,\n",
    "    '$40K - $60K': 2,\n",
    "    '$60K - $80K': 3,\n",
    "    '$80K - $120K': 4,\n",
    "    '$120K +': 5\n",
    "}\n",
    "\n",
    "card_cat_dic = {\n",
    "    'Blue': 0,\n",
    "    'Silver': 1,\n",
    "    'Gold': 2,\n",
    "    'Platinum': 3\n",
    "}\n",
    "\n",
    "df['Attrition_Flag'] = df['Attrition_Flag'].map(attrition_flag_dic)\n",
    "\n",
    "df['Education_Level'] = df['Education_Level'].map(edu_level_dic)\n",
    "\n",
    "df['Income_Category'] = df['Income_Category'].map(income_cat_dic)\n",
    "\n",
    "df['Card_Category'] = df['Card_Category'].map(card_cat_dic)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5add701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Nominal Features with pandas `get_dummies` function.\n",
    "df = pd.get_dummies(df, columns=['Gender', 'Marital_Status'])\n",
    "\n",
    "encoded = list(df.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cfd356",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"4.4\"></a>\n",
    "## 4.4- Data Split to Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed44516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we extract the x Featues and y Label\n",
    "x = df.drop(['Attrition_Flag'], axis=1)\n",
    "y = df['Attrition_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 42)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31d377",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"4.5\"></a>\n",
    "## 4.5- Handling Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d79738",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca6cb29",
   "metadata": {},
   "source": [
    "> - Data is imbalanced so we're using SMOTE to balance the data because under-sampling can cause data loss and affect prediction quality when the initial data is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de13e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4fd16",
   "metadata": {},
   "source": [
    "> - Now the Data is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299c41c4",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"4.6\"></a>\n",
    "## 4.6- Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c85952",
   "metadata": {},
   "source": [
    "### Standardizing Continuous Features with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5dcd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the StandardScaler on the training data\n",
    "scaler.fit(X_train[numerical_features])\n",
    "\n",
    "# Transforming (standardize) the continuous features in the training and testing data\n",
    "X_train_cont_scaled = scaler.transform(X_train[numerical_features])\n",
    "X_test_cont_scaled = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Replacing the scaled continuous features in the original data\n",
    "X_train[numerical_features] = X_train_cont_scaled\n",
    "X_test[numerical_features] = X_test_cont_scaled\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e54636",
   "metadata": {},
   "source": [
    "--------------------------------------------------------\n",
    "<a class=\"anchor\"  id=\"5\"></a>\n",
    "# 5- Models Training and Evaluation ⚙️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers to evaluate\n",
    "classifiers = [\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=42, max_iter= 1500, n_jobs=-1)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42, n_jobs =-1)),\n",
    "    (\"AdaBoost\", AdaBoostClassifier(random_state=42)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n",
    "    (\"LightGBM\", lgb.LGBMClassifier(random_state=42, verbose=-1)),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(random_state=42, n_jobs =-1))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7208c4a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"5.1\"></a>\n",
    "## 5.1- K-fold Cross-Validation Evaluation and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac16eef",
   "metadata": {},
   "source": [
    "> Applying cross-validation through pipelines helps us thoroughly test machine learning models. It checks their performance across various data sets, ensuring a strong evaluation. By integrating feature selection within this process through pipelines, we carefully choose the best features. This method involves testing these features on different data parts, guaranteeing they work well across different situations. This meticulous approach ensures our selected features are reliable and effective, leading to a robust and widely applicable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RFE feature selector\n",
    "RFE_selector = RFE(lgb.LGBMClassifier(random_state=42, verbose=-1), n_features_to_select=12)\n",
    "\n",
    "\n",
    "# Creating lists for classifier names, mean_test_accuracy_scores, and results.\n",
    "results = []\n",
    "mean_test_accuracy_scores = []\n",
    "classifier_names = []\n",
    "\n",
    "for model_name, model in classifiers:\n",
    "    # Print model name\n",
    "    print(f\"For {model_name}:\")\n",
    "    \n",
    "    # Steps Creation\n",
    "    steps = list()\n",
    "    \n",
    "    steps.append(('feature_selector', RFE_selector))  # RFE feature selection\n",
    "    \n",
    "    steps.append((model_name, model))\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "                        \n",
    "    # 5-fold Stratified Cross-Validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation with train scores\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=cv, scoring='accuracy',n_jobs=-1, return_train_score=True)\n",
    "    \n",
    "    print(f\"Cross-validation completed successfully for {model_name}\")\n",
    "    print('*' * 50)\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        \"Model Name\": model_name,\n",
    "        \"Mean Train Accuracy\": np.mean(cv_results['train_score']),\n",
    "        \"Mean Test Accuracy\": np.mean(cv_results['test_score'])\n",
    "    })\n",
    "    \n",
    "    mean_test_accuracy_scores.append(np.mean(cv_results['test_score']))\n",
    "    classifier_names.append(model_name)\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd0ba28",
   "metadata": {},
   "source": [
    "### Mean Test Accuracy Scores by Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795826df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from the data\n",
    "data = pd.DataFrame({'Classifier': classifier_names, 'Test Accuracy': mean_test_accuracy_scores})\n",
    "\n",
    "# Creating Plotly bar chart\n",
    "fig = px.bar(data, x='Test Accuracy', y='Classifier', orientation='h', color='Test Accuracy',\n",
    "             title='Mean Test Accuracy Scores by Classifiers', text='Test Accuracy', color_continuous_scale='viridis')\n",
    "\n",
    "# Customizing the layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Test Accuracy',\n",
    "    yaxis_title='Classifier',\n",
    "    xaxis=dict(range=[0, 1]),\n",
    "    yaxis=dict(categoryorder='total ascending'),\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c1cd6",
   "metadata": {},
   "source": [
    "> Among the various models evaluated during cross-validation, XGBoost Classifier emerged as the top performer. It exhibited exceptional performance with a Excellent Mean Train Accuracy score and an outstanding Mean Test Accuracy score Notably, the model demonstrated no signs of overfitting, making it our chosen model for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831b948",
   "metadata": {},
   "source": [
    "## Selected Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74799f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RFE feature selector\n",
    "RFE_selector = RFE(lgb.LGBMClassifier(random_state=42, verbose=-1), n_features_to_select=12)\n",
    "\n",
    "# Fit RFE selector to the training data\n",
    "RFE_selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = np.where(RFE_selector.support_)[0]\n",
    "\n",
    "# Get the names of the selected features based on their indices\n",
    "selected_feature_names = X_train.columns[selected_feature_indices]\n",
    "\n",
    "# Print the names of the selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddfc7d8",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"5.2\"></a>\n",
    "## 5.2- Training the Chosen Model (XGBoost Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with the feature selector\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('feature_selector', RFE_selector),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(random_state=42, n_jobs =-1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Printing model details\n",
    "print(f'Model: XGBoost')\n",
    "print(f'Training Accuracy: {accuracy_score(y_train, pipeline.predict(X_train))}')\n",
    "print(f'Testing Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'F1-score: {f1}')\n",
    "print('------------------------------------------------------------------')\n",
    "print(f'Testing Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "print('------------------------------------------------------------------')\n",
    "print(f'Testing Classification report: \\n{classification_report(y_test, y_pred)}')\n",
    "print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eadd63",
   "metadata": {},
   "source": [
    "## Models Predictions Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d847e59",
   "metadata": {},
   "source": [
    "> - Great, XGBoost demonstrates outstanding training and testing performance, showing no signs of overfitting and achieving an impressive F1-score of 96%.\n",
    "> - Next, we'll work on improving the XGBoost model to see if we can make it more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ac332",
   "metadata": {},
   "source": [
    "--------------------------------------------------------\n",
    "<a class=\"anchor\"  id=\"6\"></a>\n",
    "# 6- Hyperparameter Tuning  🛠️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0f1a7",
   "metadata": {},
   "source": [
    "> Hyperparameter tuning with GridSearch is crucial for optimizing model accuracy, preventing overfitting, and ensuring stable, robust predictions. It saves time, enhances computational efficiency, and leads to better-informed decisions, making it indispensable in machine learning model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5112055",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'XGBoost__learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'XGBoost__n_estimators': [100, 200, 300],  \n",
    "    'XGBoost__max_depth': [3, 4, 5],  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[]\n",
    "steps.append(('feature_selector', RFE_selector))\n",
    "steps.append((\"XGBoost\", xgb.XGBClassifier(random_state=42, n_jobs =-1)))\n",
    "pipeline=Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41571a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GridSearchCV instance\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "# Fit the pipeline with GridSearch to the data\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a65eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean test score and mean train score for the best estimator\n",
    "mean_test_score = grid_search.cv_results_['mean_test_score'][grid_search.best_index_]\n",
    "mean_train_score = grid_search.cv_results_['mean_train_score'][grid_search.best_index_]\n",
    "\n",
    "print(\"Mean Test Score:\", mean_test_score)\n",
    "print(\"Mean Train Score:\", mean_train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c329429",
   "metadata": {},
   "source": [
    "> The initial settings for XGBoost worked well, and even after trying different configurations, we didn't see much improvement in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8937554",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3db92b5",
   "metadata": {},
   "source": [
    "<a class=\"anchor\"  id=\"6.1\"></a>\n",
    "## 6.1- ROC Curve for Final Model (XGBoost Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9665ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the positive class using the final model\n",
    "y_probabilities = final_model.predict_proba(x)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(y, y_probabilities)\n",
    "auc = roc_auc_score(y, y_probabilities)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "sns.set(style='whitegrid')\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for XGBoost Classifier')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ec7a7",
   "metadata": {},
   "source": [
    "> An ROC curve with AUC = 1.00 means a perfect classifier. For the XGBoost Classifier, it signifies the model makes no classification errors, distinguishing all positive and negative cases perfectly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
